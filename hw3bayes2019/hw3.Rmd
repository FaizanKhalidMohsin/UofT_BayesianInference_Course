---
title: "Applied Bayesian Analysis Assignment 3"
author: "Faizan Khalid Mohsin"
date: "March 14, 2019"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1

## Question 1 a


```{r}

 
library(R2OpenBUGS)
 
#
# 
#data from Healy, page 90.
#  (MJR Healy, 1988, Glim: An Introduction, Clarendon Press: Oxford.)
#  Looking to see if Smoking is a risk factor for hypertension, controlling for obesity, snoring, and gender
#  Note 1: there was no males or females who were smokers and obese and who did not snore (so 1 1 0 had no exposures)
#  Note 2: here we are simply looking at the effect of smoking given the other factors.  We are ignoring the possibility that 
#  obesity might be related to smoking or that snoring might be strongly effected by smoking and obesity.  
#  In modern epi, these factors might be consider to be in the <<causal path>> and perhaps you might not control for them in this way.
cat(
"smoke  obese  snore male hypoten n
0 0 0 1 5 60
0 0 0 0 10 149
1 0 0 1 2 17
1 0 0 0 6 16
0 1 0 1 1 12
0 1 0 0 2 9
0 0 1 1 36 187
0 0 1 0 28 138
1 0 1 1 13 85
1 0 1 0 4 39
0 1 1 1 15 51
0 1 1 0 11 28
1 1 1 1 8 23
1 1 1 0 4 12
", file= "SmokeHyperData.txt")

 
SmokeHyper=read.table("SmokeHyperData.txt",header=TRUE,sep = "")
attach(SmokeHyper)


  
cat("
model{
  for( i in 1:14){
   hypoten[i] ~ dbin(mu[i], n[i])
   logit(mu[i]) <- b0 + b.smok*smoke[i]+ b.ob*obese[i]+ b.sn*snore[i] + 
     b.male*male[i] + b.smsn*smoke[i]*snore[i] + b[i]
    b[i] ~dnorm(0, tau.b)
   }
  b.smok ~ dnorm(0, .04) # so, sd =5.  exp(5) ~ 148 which is huge
  b.ob ~ dnorm(0, .04) 
  b.sn ~ dnorm(0, .04) 
  b.male ~ dnorm(0, .04) 
  b0 ~ dnorm(0, .04) 
  b.smsn ~dnorm(0, .04)
  sd.b ~ dunif(0, 5)
  tau.b <- 1/sd.b/sd.b
  }
  ", file="SmokeHyperMod3.txt")
  
  
bugM3.dat=list("hypoten", "n", "smoke", "obese", "snore", "male")  # what variable you need in the model

initM3.fun=function(){ list(  b=runif(14,-.8,-.2), 
    b0=runif(1,-.8,-.2),
    b.smok=runif(1,-.8,-.2),b.ob=runif(1,-.8,-.2), b.sn=runif(1,-.8,-.2),
	b.male=runif(1,-.8,-.2), b.smsn=runif(1, -8,-.2), sd.b=runif(1,.2,.8)	
    ) }

	
```


```{r}


paramsM3=c("b.smok", "b.ob" , "sd.b")

SmokeHypeBaseM3=bugs(bugM3.dat, initM3.fun, paramsM3, model.file="SmokeHyperMod3.txt",
                      n.chains=3, n.iter=15000, n.burnin=1,
                      n.thin=1 , debug=TRUE
)

print(SmokeHypeBaseM3,dig=3) # Summary statistics

```

```{r}

SArray= SmokeHypeBaseM3$sims.array
vname=attr(SArray,"dimnames")[3][[1]]
chainL=attr(SArray,"dim")[1][[1]]
for(i in 1:length(vname)){ 
    nn=vname[i]
    plot(density(SArray[,,nn]), main=nn)
    xnul=locator(1)    
    acf( SArray[,1,nn], main=nn)  #note: this is only for 1st chain
    xnul=locator(1)
    matplot(1:chainL,SArray[,,nn], main=nn,xlab="index",type="l")
    xnul=locator(1)
}


```


From the trace plots, we can see that the chains are traversing the sample space in the same way, therefore they seem to have converged. We can see from the density plots that they have converged to the high probability region for all parameters being monitored.
Also, the autocorrelation plots show that the chains are independently converging.


## Question 1 b

Burning first 4000 observations

```{r}

SmokeHypeBaseM4=bugs(bugM3.dat, initM3.fun, paramsM3, model.file="SmokeHyperMod3.txt",
                     n.chains=3, n.iter=15000, n.burnin=4000,
                     n.thin=1 , debug=TRUE)
print(SmokeHypeBaseM4,dig=3)


```

Autocorrelation and trace plots.

```{r}
SArray= SmokeHypeBaseM4$sims.array
vname=attr(SArray,"dimnames")[3][[1]]
chainL=attr(SArray,"dim")[1][[1]]
for(i in 1:length(vname)){ 
    nn=vname[i]
    plot(density(SArray[,,nn]), main=nn)
    xnul=locator(1)    
    acf( SArray[,1,nn], main=nn)  #note: this is only for 1st chain
    xnul=locator(1)
    matplot(1:chainL,SArray[,,nn], main=nn,xlab="index",type="l")
    xnul=locator(1)
}
```

After a burn-in of 4000 iterations, looking at the density and trace plots of all the parameters, the chains seem to have converged since they move similarly from the start over the sample space. Also, they are in the high probability region, depicted by the density plots.

## Question 1 c

If you thinned the chain, what would be the advantages? Is it necessary to thin a chain?

```{r}

SmokeHypeBaseM5=bugs(bugM3.dat, initM3.fun, paramsM3, model.file="SmokeHyperMod3.txt",
                      n.chains=3, n.iter=15000, n.burnin=4000,
                      n.thin=4 , debug=TRUE
)

```


```{r}
SArray= SmokeHypeBaseM5$sims.array
vname=attr(SArray,"dimnames")[3][[1]]
chainL=attr(SArray,"dim")[1][[1]]
for(i in 1:length(vname)){ 
    nn=vname[i]
    plot(density(SArray[,,nn]), main=nn)
    xnul=locator(1)    
    acf( SArray[,1,nn], main=nn)  #note: this is only for 1st chain
    xnul=locator(1)
    matplot(1:chainL,SArray[,,nn], main=nn,xlab="index",type="l")
    xnul=locator(1)
}
```

Thinning helps in this case, where we have 15000 iterations. It is efficient here in reducing the autocorrelation.

From trace and autocorrelation plots, which are given below, we can see that thinning helps us get rid of the autocorrelation, especially in the case of sd.b parameter. These chains mix better, and will produce a more precise estimate of the sample. 


## Question 1 d

Provide the estimate of the posterior mean of the three parameters for each chain and also give the Monte Carlo accuracy of your estimate. For the Monte Carlo accuracy, compute by batch means and by using the autocorrelation function.

Model used  here has been thinned by a factor of 4, with 15000 iterations

```{r}
library(coda)
make.mcmc.list=function(x){
   aa=x$sims.array
   zz=list(list())
   for(i in 1:(dim(aa)[2]) ){
     tmp=mcmc(aa[,i,])
     zz=c(zz,list(tmp))   }
   res=mcmc.list(zz[-1])
   res
}

wave0=make.mcmc.list(SmokeHypeBaseM5)

```


```{r}

# Provide the estimate of the posterior mean of the three parameters for each chain

for (i in 1:3){
  summary(wave0[i]); batchSE(wave0[i]); effectiveSize(wave0[i])# chain i
}
  
```

Observing the distribution of the same parameters in each chain, we can see that they seem to converge to the high probability region for each chain from the summary statistics, and the small batch standard error calculated/shown point towards estimates with high precision.


## Question 1 e



```{r}

gelman.diag(wave0[-3])

```

Gelman diagnostic gives a value of 1 for the PSRF that shows that the mcmc algorithm has converged well.

```{r}
geweke.diag(wave0)
```

Using the Geweke diagnostic to check algorithm convergence, we see that the values generated are not that high for z-scores, therefore the algorithm seems to converge well. 

## Question 1 f

The mcmc algorithm seems to have converged well after thinning as the autocorrelation is reduced, trace plots seem to cross over in the high probability regions, and the diagnostic measures such as the gelman or geweke show no alarming measure sizes.


# Question 2

## Questin 2 a 

```{r}

cropdata = data.frame(x=c(16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46), y=c(2508,2518,3304,3423,3057,3190,3500,3883,3823,3646,3708, 3333,3517,3241,3103,2776))
x=c(16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46)
y=c(2508,2518,3304,3423,3057,3190,3500,3883,3823,3646,3708, 3333,3517,3241,3103,2776)
attach(cropdata)
mean(x); sd(x)
mean(y); sd(y)
mean(x^2);sd(x^2)
oy <- y


cat("
    ### model1
    model{
    
    for( i in 1:16){
    
    sx1[i]<- (x[i]-31)/9.52
    y[i]<-  (oy[i]-3283.125)/418.3434
    
    
    y[i]~dnorm(mu[i],tau)
    mu[i]<- beta[1]+beta[2]*(sx1[i])  
    
    
    ######################################
    #        model checking steps are here.........
    
    #   getting the residuals for the observed values...
    #   note: I am deviating from the bugs manual... not getting the moments.
    
    res[i]<-(y[i]-mu[i])                 #  estimate of the residuals for this model
    stdres[i]<-res[i]*sqrt(tau)        #  for the standardized residuals
    
    dev1.obs[i]<-pow(res[i],2)
    dev2.obs[i]<-pow(stdres[i],2)
    
    #  getting a replicated sample..... This is a sample of the predictive distribution
    
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <-step(y[i]-y.rep[i])       # check to see the probability of getting a more extreme value
    
    #  residual and moments of replicated data....   this gives the predicted distribution for these values.
    res.rep[i]<- y.rep[i] - mu[i]
    stdres.rep[i]<- res.rep[i]*sqrt(tau)
    
    dev1.rep[i]<-pow(res.rep[i],2)
    dev2.rep[i]<-pow(stdres.rep[i],2)
    
    #  likelihood for each observed and replicated data....
    #  note: need to know the density function of the probability model
    loglike[i]<-  (0.5)*log(tau/6.283) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])               #  this is to find the predictive ordinate of the observations	
    
    }
    
    beta[1]~dnorm(0,0.0625)
    beta[2]~dnorm(0,0.0625)
    
    
    
    ##############################
    #     summing the diagnostic values
    
    chidev1.obs <- sum(dev1.obs[])
    chidev2.obs <- sum(dev2.obs[])
    
    chidev1.rep <- sum( dev1.rep[] )
    chidev2.rep <- sum( dev2.rep[] )
    
    chidev1.pval<-step(chidev1.obs-chidev1.rep)
    chidev2.pval<-step(chidev2.obs-chidev2.rep)
    
    #   Deviance statistic
    dev<-   -2*sum(loglike[])
    dev.rep <-  -2*sum(loglike.rep[])
    dev.pval<-step(dev-dev.rep)
    
  
    tau~dgamma(.5,.01)
    
    #abeta[1]<-beta[1]*9.52/418.34
    abeta[2]<-beta[2]*9.52/418.34
    #abeta[3]<-beta[3]*12.549/79.976
    #abeta[4]<-beta[4]*4.658/79.976
    
    }
    
    ", file="cropMod1.txt")
data<-list("x", "oy")

inits<-function(){ list(beta=rnorm(2), tau=runif(.5,1),y.rep=rnorm(16))} 

parameters<-c("beta", "tau",# the rest are for the model checking
              "mu","res", "stdres", "res.rep", "stdres.rep", "p.smaller",
              "p.inv", "chidev1.pval", "chidev2.pval", "chidev1.obs", "chidev2.obs",
              "chidev1.rep", "chidev2.rep", "dev", "dev.rep", "dev.pval")


cropMod1.sim<-bugs(data,inits, parameters,model.file="cropMod1.txt",
                   n.chains=3, n.iter=10000, n.burnin=700,
                   n.thin=1 #,debug=TRUE
)                   

##MODEL 2
mean(x^2)
sd(x^2)

cat("
    ### model2
    model{
    
    for( i in 1:16){
    
    sx1[i]<- (x[i]-31)/9.52
    sx2[i]<- (pow(x[i],2)-1046)/595.496
    y[i]<-  (oy[i]-3283.125)/418.3434
    
    
    y[i]~dnorm(mu[i],tau)
    mu[i]<- beta[1]+beta[2]*(sx1[i]) + beta[3]*(sx2[i])  
    
    
    ######################################
    #        model checking steps are here.........
    
    #   getting the residuals for the observed values...
    #   note: I am deviating from the bugs manual... not getting the moments.
    
    res[i]<-(y[i]-mu[i])                 #  estimate of the residuals for this model
    stdres[i]<-res[i]*sqrt(tau)        #  for the standardized residuals
    
    dev1.obs[i]<-pow(res[i],2)
    dev2.obs[i]<-pow(stdres[i],2)
    
    #  getting a replicated sample..... This is a sample of the predictive distribution
    
    y.rep[i]~dnorm(mu[i],tau)
    p.smaller[i] <-step(y[i]-y.rep[i])       # check to see the probability of getting a more extreme value
    
    #  residual and moments of replicated data....   this gives the predicted distribution for these values.
    res.rep[i]<- y.rep[i] - mu[i]
    stdres.rep[i]<- res.rep[i]*sqrt(tau)
    
    dev1.rep[i]<-pow(res.rep[i],2)
    dev2.rep[i]<-pow(stdres.rep[i],2)
    
    #  likelihood for each observed and replicated data....
    #  note: need to know the density function of the probability model
    loglike[i]<-  (0.5)*log(tau/6.283) + (-0.5)*tau*pow((y[i]-mu[i]),2)
    loglike.rep[i]<-  (0.5)*log(tau/6.283) + (-0.5)*tau*pow((y.rep[i]-mu[i]),2)
    
    p.inv[i]<- 1/exp(loglike[i])               #  this is to find the predictive ordinate of the observations	
    
    }
    
    beta[1]~dnorm(0,0.0625)
    beta[2]~dnorm(0,0.0625)
    beta[3]~dnorm(0,0.0625)
    
    
    ##############################
    #     summing the diagnostic values
    
    chidev1.obs <- sum(dev1.obs[])
    chidev2.obs <- sum(dev2.obs[])
    
    chidev1.rep <- sum( dev1.rep[] )
    chidev2.rep <- sum( dev2.rep[] )
    
    chidev1.pval<-step(chidev1.obs-chidev1.rep)
    chidev2.pval<-step(chidev2.obs-chidev2.rep)
    
    #   Deviance statistic
    dev<-   -2*sum(loglike[])
    dev.rep <-  -2*sum(loglike.rep[])
    dev.pval<-step(dev-dev.rep)
    
    
    tau~dgamma(.5,.01)
    
    #abeta[1]<-beta[1]*9.52/418.34
    abeta[2]<-beta[2]*9.52/418.34
    abeta[3]<-beta[3]*595.496/418.34
    #abeta[4]<-beta[4]*4.658/79.976
    
    }
    
    ", file="cropMod2.txt")

cropMod2.sim<-bugs(data,inits, parameters,model.file="cropMod2.txt",
                   n.chains=3, n.iter=10000, n.burnin=700,
                   n.thin=1 #,debug=TRUE
)    

#BOTH MODELS are writen correctly 
print(cropMod1.sim,dig=3)
print(cropMod2.sim,dig=3)

#2a
#Dic info for model 1
#DIC info (using the rule, pD = Dbar-Dhat)
#pD = 3.084 and DIC = 49.280
#DIC is an estimate of expected predictive error (lower deviance is better).

#Dic info for model 2
#DIC info (using the rule, pD = Dbar-Dhat)
#pD = 4.088 and DIC = 28.200
#DIC is an estimate of expected predictive error (lower deviance is better).

#Model 2 has a lower DIC and deviance based on the openbugs output.

#calculating deviance
#  deviance, from model/not Openbugs intrinsic
xxx<-cropMod1.sim
xxx1<-xxx$sims.list$dev.rep
temp<-c(xxx$mean$dev,quantile(xxx1,probs=c(0.025,.975)),mean(xxx1),sd(xxx1))
names(temp)=c("Deviance","2.5%","97.5%","mean","SD");temp

xxx1<-xxx$sims.list$chidev2.rep
temp<-c(xxx$mean$chidev2.obs,quantile(xxx1,probs=c(0.025,.975)),mean(xxx1),sd(xxx1))
names(temp)=c("ChiDev2","2.5%","97.5%","mean","SD");temp


##### non calibrated ("pval-stats")

apply(xxx$sims.list$p.smaller,2,mean)
xxx$mean$chidev2.pval
xxx$mean$dev.pval


###########################
###########################

# comparing intrinsic and self calculated value for Deviance:

xxx1<-xxx$sims.list$dev
xxx2<-xxx$sims.list$deviance
temp<-rbind(
  quantile(xxx1,probs=c(0.025,.25,.5,.75,.975)),
  quantile(xxx2,probs=c(0.025,.25,.5,.75,.975)) )
rownames(temp)=c("SelfProgramed:","Openbugs Made:");temp
c(xxx$mean$deviance,xxx$mean$dev)    
Dbar<-mean(xxx1);Dbar
pd2<-0.5*var(xxx1);pd2

devNormFunc <- function(beta0, beta1, beta2, tau, x, y){
  mu<- beta0+beta1*x + beta2*x^2
  return(-2*sum(log(dnorm(y,mu,1/sqrt(tau)))))}
beta0Bar<- xxx$mean$beta0
beta1Bar<- xxx$mean$beta1
beta2Bar<- 0	
tauBar <- xxx$mean$tau
Dhat <- devNormFunc(beta0Bar, beta1Bar, beta2Bar, tauBar, x,y);Dhat 
pd1<-Dbar-Dhat;pd1

DIC1<-Dbar+pd1; DIC1
DIC2<-Dbar+pd2; DIC2

#bayes factor
xxx<-cropMod1.sim
xxx$mean$p.inv

# Getting predictive Ordinates and Pseudo m2LogL (aka: )
#  Note: difference of Pseudo-m2LogL is the PsuedoBayes Factor btw models.
#
xxx1<-xxx$mean$p.inv
PLogLI=-1*log(xxx1)
temp<-cbind(xxx1,1/xxx1,PLogLI);colnames(temp)=c("p.inv","p(x)","PLogLI");temp
Pseudom2logL= -2*sum(PLogLI);Pseudom2logL # Bayes factor


#DEVIANCE for model 2
xxx<-cropMod2.sim
xxx1<-xxx$sims.list$dev.rep
temp<-c(xxx$mean$dev,quantile(xxx1,probs=c(0.025,.975)),mean(xxx1),sd(xxx1))
names(temp)=c("Deviance","2.5%","97.5%","mean","SD");temp

xxx1<-xxx$sims.list$chidev2.rep
temp<-c(xxx$mean$chidev2.obs,quantile(xxx1,probs=c(0.025,.975)),mean(xxx1),sd(xxx1))
names(temp)=c("ChiDev2","2.5%","97.5%","mean","SD");temp


xxx1<-xxx$sims.list$dev
xxx2<-xxx$sims.list$deviance
temp<-rbind(
  quantile(xxx1,probs=c(0.025,.25,.5,.75,.975)),
  quantile(xxx2,probs=c(0.025,.25,.5,.75,.975)) )
rownames(temp)=c("SelfProgramed:","Openbugs Made:");temp

c(xxx$mean$deviance,xxx$mean$dev)    
Dbar<-mean(xxx1);Dbar
pd2<-0.5*var(xxx1);pd2

devNormFunc <- function(beta0, beta1, beta2, tau, x, y){
  mu<- beta0+beta1*x + beta2*x^2
  return(-2*sum(log(dnorm(y,mu,1/sqrt(tau)))))}
beta0Bar<- xxx$mean$beta0
beta1Bar<- xxx$mean$beta1
beta2Bar<- 0	
tauBar <- xxx$mean$tau
Dhat <- devNormFunc(beta0Bar, beta1Bar, beta2Bar, tauBar, x,y);Dhat 
pd1<-Dbar-Dhat;pd1

DIC1<-Dbar+pd1; DIC1
DIC2<-Dbar+pd2; DIC2

#bayes factor
xxx<-cropMod2.sim
xxx$mean$p.inv

# Getting predictive Ordinates and Pseudo m2LogL (aka: )
#  Note: difference of Pseudo-m2LogL is the PsuedoBayes Factor btw models.
#
xxx1<-xxx$mean$p.inv
PLogLI=-1*log(xxx1)
temp<-cbind(xxx1,1/xxx1,PLogLI);colnames(temp)=c("p.inv","p(x)","PLogLI");temp
Pseudom2logL= -2*sum(PLogLI);Pseudom2logL # Bayes factor


```

Notice that DIC, deviance and bayes factor measures are lower for model 2 which is the quadratic model, and therefore model 2 is preferred.

From  Openbugs output
Dic info for model 1
pD = 3.084 and DIC = 49.280

Dic info for model 2
pD = 4.088 and DIC = 28.200


### MODEL 1

From the above output we obtain the following:

The Deviance:

Deviance  2.5%      97.5%     mean      SD
--------- --------- --------- --------- --------
46.204683 30.400000 62.880000 45.288958 8.305494 
--------- --------- --------- --------- --------

The ChiDev2:

ChiDev2   2.5%     97.5%     mean       SD 
--------- -------- --------- --------- ---------
16.963055 6.884000 28.825250 16.047275  5.662972 
--------- -------- --------- --------- ---------

And lastlly:

X              2.5% 25%   50%   75%   97.5%
-------------- ---- ----- ----- ----- -----
SelfProgramed: 43.3 44.34 45.55 47.36 52.78
Openbugs Made: 43.3 44.34 45.55 47.36 52.78
-------------- ---- ----- ----- ----- -----

SELF programmed and OPENBUGS MEANS for Deviance are
46.20517 46.20468


$DIC2<-Dbar+pd2; DIC2$ DIC
49.4639

$Pseudom2logL= -2*sum(PLogLI);Pseudom2logL$ Pseudo-Bayes factor
50.11571


### MODEL 2

From the above output we obtain the following:

The Deviance:

Deviance  2.5%      97.5%     mean      SD
--------- --------- --------- --------- --------
24.109448  7.946900 41.525250 23.232516 8.572244  
--------- --------- --------- --------- --------

The ChiDev2:

ChiDev2   2.5%     97.5%     mean       SD 
--------- -------- --------- --------- ---------
16.905456 6.950850 28.970000 16.028472 5.649806 
--------- -------- --------- --------- ---------

And lastlly:

X              2.5% 25%   50%   75%   97.5%
-------------- ---- ----- ----- ----- -----
SelfProgramed: 19.67 21.53 23.31 25.83 33.17
Openbugs Made: 19.67 21.53 23.31 25.83 33.17
-------------- ---- ----- ----- ----- -----

SELF programmed and OPENBUGS MEANS for Deviance are
24.10992 24.10945

$DIC2<-Dbar+pd2; DIC2$ DIC
30.41021

$Pseudom2logL= -2*sum(PLogLI);Pseudom2logL$ Pseudo-Bayes factor
28.04221

BAYES-FACTOR CALCULATION

```{r}

# MODEL for Bayes factor calculation

cat("
    ### model3
    model{
    for( i in 1:16){
    sx1[i]<- (x[i]-31)/9.52
    sx2[i]<- (pow(x[i],2)-1046)/595.496
    y[i]<-  (oy[i]-3283.125)/418.3434
    y[i]~dnorm(mu[i],tau)
    mu[i]<-  del[1]*beta[1]*(sx1[i]) + del[2]*beta[2]*(sx2[i])
     }
    beta[1]~dnorm(0,0.0625)
    beta[2]~dnorm(0,0.0625)
    tau~dgamma(.5,.01)
    for(k in 1:2){del[k]~dbern(0.5)}
    for(i1 in 1:2){
    for(i2 in 1:2){
    mod[i1,i2]<-equals((2-i1),del[1])*equals( (2-i2),del[2])
    }}
    }    
    ", file="cropMod3.txt")

inits1<-function(){ list(beta=rnorm(3), del=c(1,2) ,tau=runif(.5,1),y.rep=rnorm(16))} 

parameters1<-c("mod","del","beta")

cropMod3.sim<-bugs(data,inits1, parameters1,model.file="cropMod3.txt",
                   n.chains=3, n.iter=10000, n.burnin=700,
                   n.thin=1 #,debug=TRUE
                   )

print(cropMod3.sim, dig=5) # printing model probabilities
```

BAYES FACTOR

We take Model(1,1) and Model (1,2) probabilities from the output above to get the Bayes factor.

```{r}

2*log(.94/.005) #BAYES FACTOR

```

The above calculation 2log(BF)=10.47, shows that the quadratic model is an
improvement over the linear model.


## Question 2 b

For model 1, calculate 1) the residuals, 2) the standardized residuals, and 3) the chance of getting a more extreme observation. Comment on the results of these statistics for the observation. Also, comment on how well you think the model fits the data.


Below we calculate the residuals and distribution of the statistics under the predicted distribution. 

```{r}

xxx<-cropMod1.sim
temp<-cbind(xxx$mean$res,t(apply(xxx$sims.list$res.rep,2,function(x){c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
colnames(temp)=c("res","2.5%","97.5%","mean","SD");temp

```

Below we calculate the STANDARD RESIDUALS and distribution of the statistics under the predicted distribution.


```{r}
temp<-cbind(xxx$mean$stdres,t(apply(xxx$sims.list$stdres.rep,2,function(x)
{c(quantile(x,probs=c(0.025,.975)),mean(x),sd(x))})))
colnames(temp)=c("stdres","2.5%","97.5%","mean","SD");temp

```

Below we calculate the PROBABILITY of extreme values.

```{r}
apply(xxx$sims.list$p.smaller,2,mean)
```

The mean of the residuals is within the 95% Cis of the residuals, which shows that the model fits the data well. 


# Question 3 

## Question 3 a 

```{r}
u1<-runif(1000 ,0,1) # Sampling from a uniform
u2<-runif(1000 ,0,1) # Sampling from a uniform
x<- (u1+u2)/2 # Adding the 2 uniform distributions
c(mean(x),var(x)) # Mean and Variance

```


## Question 3 b


```{r}

u1<-runif(1000 ,0,1) # Sampling from a uniform
g=function(x){(x>0)*(x<1)*((x<=0.5)*4*x+ (x>0.5)*(4-4*x))}
gu1<- g(u1)
fu1<- 1*(u1>=0)*(u1<=1)
# weight function is gu1/fu1 
w<-(gu1/fu1) # Weight function
c(mean(u1*w),var(u1*w)) # Mean and Variance based on importance sampling

```


## Question 3 c

Acceptance-rejection method

```{r}
x <- runif(1000)
Y <- rep(0,1000)
accept = c()
for(i in 1:length(x)){
 U = runif(1)
 if(U <= ( g(x[i]) / (2*dunif(x[i])) ) ){
   Y[i] = x[i]
   accept[i] ="Yes"
 }
 else {
   accept[i] = "No" 
   Y[i]<- 888
 }
}

mean(accept == "Yes") #Acceptance rate

c(mean(Y[Y<888]),var(Y[Y<888])) #Mean and variance of y's that were accepted
```

The above algorithm is sampling from g(x) and generating sample using a uniform distribution, with a constant.

If U<= g/(some constant)*f(x), we sample the observation.
So, the algorithm above picks out the (X, U) points which are sampled by X ∼ f(x)=uniform and U ∼ Unif(0, 1) which are “under” the g(x) curve.


## Question 3 d 

Metropolis Hasting Algorithm


```{r, results="hide"}
q1 <- function(x,y){(y>=0)*(y<=1)*1} # THIS IS q(x,y)

g=function(x){(x>0)*(x<1)*((x<=0.5)*4*x+ (x>0.5)*(4-4*x))} #this is our u(x)

alph = function (x,y){min(g(y)/g(x),1)} #TEST FUNCTION

#R-code to sample the chain
x < - rep (0,1000)
x[1]<-0.5
accepted<- c()
for (j in 2:1000){
 ystar <- runif(1)
 T <- runif(1)
 if (T<= alph(x[j-1],ystar)){
   x[j]<- ystar
   accepted[j]<- "Yes"
   }
 else{
   x[j]<- x[j-1]
   accepted[j]<- "No"
 }
}

```

The mean, variance and acceptance rate.

```{r}

mean(x) # Mean
var(x) # Variance
mean(accepted=="Yes",na.rm=TRUE) # Acceptance rate

```


